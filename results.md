```
Bench mark
(py310) yyfsss@DESKTOP-86MTRK8:~/FLARE-Med/MIRAGE$ python src/evaluate.py --config src/config.json
Loaded configuration from src/config.json

Final arguments:
corpus_name: MedText
retriever_name: RRF-4
llm_name: OpenAI/gpt-4.1-nano
rag: True
k: 32
results_dir: ./prediction
dataset_name: mmlu

[mmlu] mean acc: 0.8476; proportion std: 0.0109
[Average] mean acc: 0.8476


```

